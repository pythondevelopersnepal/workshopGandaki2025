{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68594116",
   "metadata": {},
   "source": [
    "### The IMDb dataset is a binary sentiment classification dataset with 50,000 movie reviews (25,000 for training and 25,000 for testing), evenly split between positive and negative sentiments. We’ll use an RNN with LSTM layers to train a model that classifies reviews as positive (1) or negative (0). LSTMs are well-suited for this task because they can capture long-term dependencies in sequential text data, overcoming limitations of traditional RNNs like vanishing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0094a19b",
   "metadata": {},
   "source": [
    "### Steps\n",
    "- Load and Preprocess the Dataset: Use TensorFlow’s built-in IMDb dataset, preprocess the text by tokenizing and padding sequences.\n",
    "- Build the Model: Create an RNN-LSTM model using Keras.\n",
    "- Train the Model: Train on the training set and validate on a portion of it.\n",
    "- Evaluate the Model: Test the model’s performance on the test set.\n",
    "- User Input Section: Allow users to input custom text and predict its sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff13f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "# 1. Load and Preprocess the IMDb Dataset\n",
    "max_words = 10000  # Use the top 10,000 most frequent words\n",
    "max_len = 200      # Maximum length of each review (truncate/pad to this length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc56d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 16s 1us/step\n",
      "Training samples: 25000, Test samples: 25000\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)\n",
    "\n",
    "# Pad sequences to ensure uniform input length\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# Print dataset info\n",
    "print(f\"Training samples: {len(x_train)}, Test samples: {len(x_test)}\")\n",
    "\n",
    "# 2. Build the RNN-LSTM Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.5))  # Prevent overfitting\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification (positive/negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53a0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 64)           49408     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200, 64)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,341,857\n",
      "Trainable params: 1,341,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 133s 206ms/step - loss: 0.4024 - accuracy: 0.8186 - val_loss: 0.3036 - val_accuracy: 0.8746\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 160s 256ms/step - loss: 0.2497 - accuracy: 0.9041 - val_loss: 0.3409 - val_accuracy: 0.8648\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 154s 246ms/step - loss: 0.1857 - accuracy: 0.9313 - val_loss: 0.3534 - val_accuracy: 0.8674\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 150s 240ms/step - loss: 0.1274 - accuracy: 0.9561 - val_loss: 0.3934 - val_accuracy: 0.8546\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 146s 233ms/step - loss: 0.0959 - accuracy: 0.9696 - val_loss: 0.4771 - val_accuracy: 0.8394\n",
      "\n",
      "Test Loss: 0.5046, Test Accuracy: 0.8358\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# 3. Train the Model\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 4. Evaluate the Model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380401d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 6s 4us/step\n",
      "\n",
      "--- Sentiment Prediction for User Input ---\n",
      "Enter a movie review (or 'quit' to exit): This movie is good\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Sentiment: Positive (Confidence: 0.5483)\n",
      "Enter a movie review (or 'quit' to exit): This movie is bad\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Predicted Sentiment: Positive (Confidence: 0.5359)\n"
     ]
    }
   ],
   "source": [
    "# 5. User Input Section\n",
    "def preprocess_text(text, word_index, max_len):\n",
    "    # Convert text to sequence of word indices\n",
    "    tokens = text.lower().split()\n",
    "    sequence = [word_index.get(word, 0) if word in word_index and word_index[word] < max_words else 0 for word in tokens]\n",
    "    # Pad the sequence\n",
    "    padded_sequence = pad_sequences([sequence], maxlen=max_len)\n",
    "    return padded_sequence\n",
    "\n",
    "# Get the word index from the IMDb dataset\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "print(\"\\n--- Sentiment Prediction for User Input ---\")\n",
    "while True:\n",
    "    user_text = input(\"Enter a movie review (or 'quit' to exit): \")\n",
    "    if user_text.lower() == 'quit':\n",
    "        break\n",
    "    # Preprocess user input\n",
    "    processed_input = preprocess_text(user_text, word_index, max_len)\n",
    "    # Predict sentiment\n",
    "    prediction = model.predict(processed_input)[0][0]\n",
    "    sentiment = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
    "    print(f\"Predicted Sentiment: {sentiment} (Confidence: {prediction:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9086d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
